# CSV Data Analysis Tutorial for Beginners

This repository contains a complete tutorial for learning how to extract, manipulate, and analyze data from CSV files using Python and pandas.

## ðŸ“ Files in this Repository

1. **`generate_csv.py`** - Creates a sample CSV file with fake customer data using the Faker library
2. **`csv_analysis_tutorial.py`** - Complete tutorial showing all essential CSV operations
3. **`sample_customer_data.csv`** - Sample dataset (generated by the first script)
4. **`README.md`** - This file with instructions

## ðŸ› ï¸ Prerequisites

Before running the scripts, install the required libraries:

```bash
pip install faker pandas numpy matplotlib seaborn
```

## ðŸš€ Getting Started

### Step 1: Generate Sample Data
Run the first script to create your sample CSV file:

```bash
python generate_csv.py
```

This will create `sample_customer_data.csv` with 1000 fake customer records including:
- Customer information (name, email, phone, age)
- Location data (city, country)
- Professional data (job title, salary, department)
- Customer behavior (orders, spending, activity status)
- Timestamps (registration date, last login)

### Step 2: Run the Analysis Tutorial
Execute the main tutorial script:

```bash
python csv_analysis_tutorial.py
```

This will walk you through all essential data analysis operations step by step.

## ðŸ“š What You'll Learn

### 1. **Data Loading and Exploration**
- How to load CSV files with pandas
- Understanding dataset structure (shape, columns, data types)
- Previewing data with `head()` and `tail()`
- Getting dataset information with `info()`

### 2. **Data Quality Assessment**
- Checking for missing values
- Identifying duplicate records
- Understanding data types and their implications

### 3. **Basic Statistics and Summaries**
- Descriptive statistics for numerical columns
- Value counts for categorical columns
- Understanding data distribution

### 4. **Data Filtering and Selection**
- Selecting specific columns
- Filtering rows based on conditions
- Using multiple conditions with logical operators
- Working with boolean masks

### 5. **Data Grouping and Aggregation**
- Grouping data by categories
- Computing aggregated statistics (mean, sum, count, etc.)
- Multi-level grouping
- Creating summary reports

### 6. **Data Transformation**
- Creating new columns from existing data
- Applying functions to transform data
- Categorizing continuous variables
- Working with text data (concatenation, manipulation)

### 7. **Sorting and Ranking**
- Sorting by single or multiple columns
- Finding top/bottom values
- Ranking data points

### 8. **Data Export**
- Saving processed data to new CSV files
- Exporting specific columns
- Creating summary reports

## ðŸ’¡ Key Python Libraries Used

- **pandas**: Primary library for data manipulation and analysis
- **numpy**: Numerical operations and array handling
- **faker**: Generating realistic fake data for practice
- **matplotlib/seaborn**: Data visualization (for advanced examples)

## ðŸŽ¯ Sample Operations You'll Master

```python
# Load data
df = pd.read_csv('sample_customer_data.csv')

# Basic exploration
print(df.shape)
print(df.head())
print(df.info())

# Filtering data
high_spenders = df[df['total_spent'] > 2000]
active_customers = df[df['is_active'] == True]

# Grouping and aggregation
avg_spending = df.groupby('customer_segment')['total_spent'].mean()

# Creating new columns
df['spending_per_order'] = df['total_spent'] / df['orders_count']

# Sorting data
top_customers = df.nlargest(10, 'total_spent')
```

## ðŸ“Š Sample Dataset Structure

The generated CSV contains the following columns:

| Column | Description | Type |
|--------|-------------|------|
| customer_id | Unique customer identifier | Integer |
| first_name | Customer's first name | String |
| last_name | Customer's last name | String |
| email | Email address | String |
| phone | Phone number | String |
| age | Customer age | Integer |
| city | City name | String |
| country | Country name | String |
| job_title | Professional title | String |
| salary | Annual salary | Integer |
| registration_date | Account creation date | Date |
| last_login | Last login timestamp | DateTime |
| orders_count | Number of orders placed | Integer |
| total_spent | Total money spent | Float |
| customer_segment | Customer tier (Bronze/Silver/Gold/Platinum) | String |
| is_active | Account status | Boolean |
| department | Work department | String |

## ðŸŽ“ Learning Path

1. **Beginner**: Start with data loading, exploration, and basic filtering
2. **Intermediate**: Move to grouping, aggregation, and data transformation
3. **Advanced**: Practice complex queries, data cleaning, and analysis workflows

## ðŸ”§ Common Patterns You'll Use

- **Data Loading**: `pd.read_csv(filename)`
- **Data Exploration**: `df.shape`, `df.info()`, `df.describe()`
- **Filtering**: `df[condition]` or `df.query('condition')`
- **Grouping**: `df.groupby('column').agg(function)`
- **New Columns**: `df['new_col'] = df['col1'] + df['col2']`
- **Sorting**: `df.sort_values('column', ascending=False)`
- **Saving**: `df.to_csv('filename.csv', index=False)`

## ðŸŒŸ Next Steps

After completing this tutorial, you'll be ready to:
- Analyze your own CSV datasets
- Perform data cleaning operations
- Create data visualizations
- Build data analysis pipelines
- Work with larger and more complex datasets

## ðŸ“ž Need Help?

This tutorial is designed to be self-explanatory with plenty of comments and explanations. Each section builds on the previous one, so work through them in order.

Happy learning! ðŸš€
